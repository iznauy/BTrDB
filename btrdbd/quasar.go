package btrdbd

import (
	"fmt"
	"github.com/cespare/xxhash"
	"sync"
	"time"

	"github.com/iznauy/BTrDB/inter/bstore"
	"github.com/iznauy/BTrDB/qtree"
	"github.com/op/go-logging"
	"github.com/pborman/uuid"
)

var log *logging.Logger

func init() {
	log = logging.MustGetLogger("log")
}

type openTree struct {
	// ç¼“å†²åŒº
	store  qtree.Buffer
	id     uuid.UUID
	sigEC  chan bool // æå‰æäº¤çš„æ—¶å€™å¾€è¿™ä¸ªé‡Œé¢å‘ä¸ªæ¶ˆæ¯ï¼Œè®©å½“æ¬¡çš„å®šæœŸä»»åŠ¡ä¸å†æ‰§è¡Œ
	policy BufferPolicy
}

type forest struct {
	mu        sync.RWMutex             // å…¨å±€é”
	treeLocks map[[16]byte]*sync.Mutex // ðŸŒ²é”
	openTrees map[[16]byte]*openTree   // æ¯ä¸ªæ—¶é—´åºåˆ—å¯¹åº”è‡ªå·±çš„ç¼“å†²åŒº
	q         *Quasar
}

func (f *forest) getTree(id uuid.UUID) (*openTree, *sync.Mutex) {
	mk := bstore.UUIDToMapKey(id)
	f.mu.RLock()
	ot, ok := f.openTrees[mk]
	if !ok {
		f.mu.RUnlock()
		f.mu.Lock()
		if ot, ok := f.openTrees[mk]; ok {
			mtx, _ := f.treeLocks[mk]
			f.mu.Unlock()
			return ot, mtx
		}
		ot := newOpenTree(id)
		mtx := &sync.Mutex{}
		f.openTrees[mk] = ot
		f.treeLocks[mk] = mtx
		f.mu.Unlock()
		mtx.Lock()
		ot.policy = &NaiveBufferPolicy{}
		ot.policy.InitPolicy(f.q, ot)
		mtx.Unlock()
		return ot, mtx
	}
	mtx, _ := f.treeLocks[mk]
	f.mu.RUnlock()
	return ot, mtx
}

func (f *forest) isPending() bool {
	isPend := false
	f.mu.Lock()
	for uuid, ot := range f.openTrees {
		f.treeLocks[uuid].Lock()
		if ot.store != nil && ot.store.Len() > 0 {
			isPend = true
			f.treeLocks[uuid].Unlock()
			break
		}
		f.treeLocks[uuid].Unlock()
	}
	f.mu.Unlock()
	return isPend
}

const MinimumTime = 0
const MaximumTime = 64 << 56
const LatestGeneration = bstore.LatestGeneration

type Quasar struct {
	cfg     QuasarConfig
	bs      *bstore.BlockStore
	forests []*forest
}

func newOpenTree(id uuid.UUID) *openTree {
	return &openTree{
		id: id,
	}
}

type QuasarConfig struct {
	//Measured in the number of datablocks
	//So 1000 is 8 MB cache
	DatablockCacheSize uint64

	//This enables the grouping of value inserts
	//with a commit every Interval millis
	//If the number of stored values exceeds
	//EarlyTrip
	TransactionCoalesceEnable    bool   // æ˜¯å¦å¼€å¯ TransactionCoalesce
	TransactionCoalesceInterval  uint64 // å¿…é¡»è¦æäº¤çš„æ—¶é—´é—´éš”
	TransactionCoalesceEarlyTrip uint64 // å¿…é¡»è¦æäº¤çš„ç‚¹çš„æ•°é‡

	ForestCount uint64

	Params map[string]string
}

// åˆ¤æ–­æ˜¯å¦æœ‰æ•°æ®åœ¨ buffer ä¹‹ä¸­
// Return true if there are uncommited results to be written to disk
// Should only be used during shutdown as it hogs the glock
func (q *Quasar) IsPending() bool {
	isPend := false
	for _, f := range q.forests {
		if f != nil && f.isPending() {
			isPend = true
			break
		}
	}
	return isPend
}

func NewQuasar(cfg *QuasarConfig) (*Quasar, error) {
	bs, err := bstore.NewBlockStore(cfg.Params)
	if err != nil {
		return nil, err
	}
	forests := make([]*forest, cfg.ForestCount)
	rv := &Quasar{
		cfg:     *cfg,
		bs:      bs,
		forests: forests,
	}
	for i := 0; i < len(forests); i++ {
		forests[i] = &forest{
			openTrees: make(map[[16]byte]*openTree, 128),
			treeLocks: make(map[[16]byte]*sync.Mutex, 128),
			q:         rv,
		}
	}
	return rv, nil
}

// èŽ·å–æŸä¸ªæ ‘çš„ç¼“å†²åŒºåŠå…¶å¯¹åº”çš„é”
func (q *Quasar) getTree(id uuid.UUID) (*openTree, *sync.Mutex) {
	return q.forests[xxhash.Sum64String(id.String())%q.cfg.ForestCount].getTree(id)
}

// æäº¤ç¼“å†²åŒºä¸­çš„æ•°æ®
func (t *openTree) commit(q *Quasar) {
	if t.store != nil && t.store.Len() == 0 {
		//This might happen with a race in the timeout commit
		fmt.Println("no store in commit")
		return
	}
	t.policy.CommitNotice()
	tr, err := qtree.NewWriteQTree(q.bs, t.id)
	if err != nil {
		log.Panic(err)
	}
	if err := tr.InsertValues(t.store); err != nil {
		log.Error("BAD INSERT: ", err)
	}
	tr.Commit()
	t.store = nil
}

// æ’å…¥æ•°æ®ç‚¹ï¼Œå¦‚æžœæ²¡è¾¾åˆ° buffer é™åˆ¶ï¼Œå°†æ•°æ®æ’å…¥åˆ° bufferï¼Œå¦åˆ™å°†ä¼šæå‰åˆ·æ–°æ•°æ®
func (q *Quasar) InsertValues(id uuid.UUID, r []qtree.Record) {
	defer func() {
		if r := recover(); r != nil {
			log.Error("BAD INSERT: ", r)
		}
	}()
	tr, mtx := q.getTree(id)
	mtx.Lock()
	if tr == nil {
		log.Panicf("This should not happen")
		return
	}
	if !q.cfg.TransactionCoalesceEnable && !tr.policy.IsNewTree() { // æ–°æ ‘å¼ºåˆ¶èšåˆ transactions
		tr.store = qtree.SliceBuffer(r)
		tr.commit(q)
		mtx.Unlock()
		return
	}
	if tr.store == nil {
		//Empty store
		bufferType := tr.policy.GetBufferType()
		switch bufferType {
		case Slice:
			tr.store = qtree.NewSliceBuffer()
		case PreAllocatedSlice:
			tr.store = qtree.NewPreAllocatedSliceBuffer(tr.policy.GetBufferMaxSize())
		case LinkedList:
			tr.store = qtree.NewLinkedListBuffer()
		default:
			log.Fatalf("unknown buffer type: %d", bufferType)
		}
		tr.sigEC = make(chan bool, 1)
		//Also spawn the coalesce timeout goroutine
		go func(abrt chan bool) {
			tmt := time.After(time.Duration(tr.policy.GetEarlyTripTime()) * time.Millisecond)
			select {
			case <-tmt:
				//do coalesce
				mtx.Lock()
				//In case we early tripped between waiting for lock and getting it, commit will return ok
				//log.Debug("Coalesce timeout %v", id.String())
				tr.commit(q)
				mtx.Unlock()
			case <-abrt:
				return
			}
		}(tr.sigEC)
	}
	tr.store.Write(r)
	if uint64(tr.store.Len()) >= tr.policy.GetBufferMaxSize() {
		tr.sigEC <- true
		log.Debug("Coalesce early trip %v", id.String())
		tr.commit(q)
	}
	mtx.Unlock()
}

// è¯»å–æŸä¸ªç‰ˆæœ¬ä¸‹æŸä¸ªæ—¶é—´åŒºé—´çš„æ‰€æœ‰æ•°æ®
//These functions are the API. TODO add all the bounds checking on PW, and sanity on start/end
func (q *Quasar) QueryValues(id uuid.UUID, start int64, end int64, gen uint64) ([]qtree.Record, uint64, error) {
	tr, err := qtree.NewReadQTree(q.bs, id, gen) // ä»Ž MongoDB ä¸­åŠ è½½è¶…çº§å—ï¼Œè¶…çº§å—åŒ…æ‹¬ç‰ˆæœ¬ä¿¡æ¯ï¼Œæ ¹èŠ‚ç‚¹åœ°å€ rootï¼Œunlinked å­—æ®µ
	if err != nil {
		return nil, 0, err
	}
	rv, err := tr.ReadStandardValuesBlock(start, end)
	return rv, tr.Generation(), err
}

// æä¾›ä¸€ä¸ªè¯»å–æ—¶é—´åŒºé—´ chan
func (q *Quasar) QueryValuesStream(id uuid.UUID, start int64, end int64, gen uint64) (chan qtree.Record, chan error, uint64) {
	tr, err := qtree.NewReadQTree(q.bs, id, gen)
	if err != nil {
		return nil, nil, 0
	}
	recordc := make(chan qtree.Record)
	errc := make(chan error)
	go tr.ReadStandardValuesCI(recordc, errc, start, end)
	return recordc, errc, tr.Generation()
}

// è¯»å–æŸä¸ªæ—¶é—´åŒºé—´çš„ç»Ÿè®¡ä¿¡æ¯
func (q *Quasar) QueryStatisticalValues(id uuid.UUID, start int64, end int64,
	gen uint64, pointwidth uint8) ([]qtree.StatRecord, uint64, error) {
	//fmt.Printf("QSV0 s=%v e=%v pw=%v\n", start, end, pointwidth)
	start &^= ((1 << pointwidth) - 1) // æ¸…ç©ºä½Žä½
	end &^= ((1 << pointwidth) - 1)
	end -= 1
	tr, err := qtree.NewReadQTree(q.bs, id, gen)
	if err != nil {
		return nil, 0, err
	}
	rv, err := tr.QueryStatisticalValuesBlock(start, end, pointwidth)
	if err != nil {
		return nil, 0, err
	}
	return rv, tr.Generation(), nil
}
func (q *Quasar) QueryStatisticalValuesStream(id uuid.UUID, start int64, end int64,
	gen uint64, pointwidth uint8) (chan qtree.StatRecord, chan error, uint64) {
	fmt.Printf("QSV1 s=%v e=%v pw=%v\n", start, end, pointwidth)
	start &^= ((1 << pointwidth) - 1)
	end &^= ((1 << pointwidth) - 1)
	end -= 1
	rvv := make(chan qtree.StatRecord, 1024)
	rve := make(chan error)
	tr, err := qtree.NewReadQTree(q.bs, id, gen)
	if err != nil {
		return nil, nil, 0
	}
	go tr.QueryStatisticalValues(rvv, rve, start, end, pointwidth)
	return rvv, rve, tr.Generation()
}

func (q *Quasar) QueryWindow(id uuid.UUID, start int64, end int64,
	gen uint64, width uint64, depth uint8) (chan qtree.StatRecord, uint64) {
	rvv := make(chan qtree.StatRecord, 1024)
	tr, err := qtree.NewReadQTree(q.bs, id, gen)
	if err != nil {
		return nil, 0
	}
	go tr.QueryWindow(start, end, width, depth, rvv)
	return rvv, tr.Generation()
}

// èŽ·å–æœ€æ–°çš„ç‰ˆæœ¬å·ä¿¡æ¯
func (q *Quasar) QueryGeneration(id uuid.UUID) (uint64, error) {
	sb := q.bs.LoadSuperblock(id, bstore.LatestGeneration)
	if sb == nil {
		return 0, qtree.ErrNoSuchStream
	}
	return sb.Gen(), nil
}

// æŸ¥è¯¢æœ€æŽ¥è¿‘çš„æ•°æ®ç‚¹
func (q *Quasar) QueryNearestValue(id uuid.UUID, time int64, backwards bool, gen uint64) (qtree.Record, uint64, error) {
	tr, err := qtree.NewReadQTree(q.bs, id, gen)
	if err != nil {
		return qtree.Record{}, 0, err
	}
	rv, err := tr.FindNearestValue(time, backwards)
	return rv, tr.Generation(), err
}

type ChangedRange struct {
	Start int64
	End   int64
}

//Resolution is how far down the tree to go when working out which blocks have changed. Higher resolutions are faster
//but will give you back coarser results.
// è¯»å–æŸä¸¤ä¸ªç‰ˆæœ¬ä¹‹é—´å˜åŒ–çš„æ—¶é—´åŒºé—´
func (q *Quasar) QueryChangedRanges(id uuid.UUID, startgen uint64, endgen uint64, resolution uint8) ([]ChangedRange, uint64, error) {
	//0 is a reserved generation, so is 1, which means "before first"
	if startgen == 0 {
		startgen = 1
	}
	tr, err := qtree.NewReadQTree(q.bs, id, endgen)
	if err != nil {
		log.Debug("Error on QCR open tree")
		return nil, 0, err
	}
	rv := make([]ChangedRange, 0, 1024)
	rch := tr.FindChangedSince(startgen, resolution)
	var lr *ChangedRange = nil
	for {
		select {
		case cr, ok := <-rch:
			if !ok {
				//This is the end.
				//Do we have an unsaved LR?
				if lr != nil {
					rv = append(rv, *lr)
				}
				return rv, tr.Generation(), nil
			}
			if !cr.Valid {
				log.Panicf("Didn't think this could happen")
			}
			//Coalesce
			if lr != nil && cr.Start == lr.End {
				lr.End = cr.End
			} else {
				if lr != nil {
					rv = append(rv, *lr)
				}
				lr = &ChangedRange{Start: cr.Start, End: cr.End}
			}
		}
	}
}

// åˆ é™¤æŸä¸ªæ—¶é—´åŒºé—´ï¼Œè¿™è¾¹æ¶‰åŠåˆ°å†™çš„é—®é¢˜
func (q *Quasar) DeleteRange(id uuid.UUID, start int64, end int64) error {
	tr, mtx := q.getTree(id)
	mtx.Lock()
	if tr.store != nil && tr.store.Len() != 0 {
		tr.sigEC <- true
		tr.commit(q) // æ‰§è¡Œåˆ é™¤æ“ä½œçš„æ—¶å€™ï¼Œå¦‚æžœè¿˜æœ‰æ²¡åˆ·æ–°çš„æ•°æ®ï¼Œå…ˆåˆ·æ–°æ•°æ®
	}
	wtr, err := qtree.NewWriteQTree(q.bs, id)
	if err != nil {
		log.Panic(err)
	}
	err = wtr.DeleteRange(start, end)
	if err != nil {
		log.Panic(err)
	}
	wtr.Commit()
	mtx.Unlock()
	return nil
}
